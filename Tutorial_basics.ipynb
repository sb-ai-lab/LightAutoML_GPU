{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this tutorial you will learn how to:\n",
    "* run LightAutoML GPU version training on tabular data\n",
    "* obtain feature importances and reports\n",
    "* configure resource usage in LightAutoML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.066681,
     "end_time": "2021-06-22T20:10:53.090975",
     "exception": false,
     "start_time": "2021-06-22T20:10:53.024294",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 0.1. Import libraries\n",
    "\n",
    "Here we will import the libraries we use in this kernel:\n",
    "- Standard python libraries for timing, working with OS etc.\n",
    "- Essential python DS libraries like numpy, pandas, scikit-learn and torch (the last we will use in the next cell)\n",
    "- LightAutoML modules: presets for AutoML, task and report generation module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:10:53.233356Z",
     "iopub.status.busy": "2021-06-22T20:10:53.232675Z",
     "iopub.status.idle": "2021-06-22T20:11:01.486841Z",
     "shell.execute_reply": "2021-06-22T20:11:01.487566Z",
     "shell.execute_reply.started": "2021-06-22T19:06:43.597648Z"
    },
    "papermill": {
     "duration": 8.32949,
     "end_time": "2021-06-22T20:11:01.487788",
     "exception": false,
     "start_time": "2021-06-22T20:10:53.158298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level \"INFO2: 17\" already defined, skipping...\n",
      "Level \"INFO3: 13\" already defined, skipping...\n",
      "'pdf' extra dependecy package 'weasyprint' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'pdf' extra dependecy package 'weasyprint' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n"
     ]
    }
   ],
   "source": [
    "# Standard python libraries\n",
    "import os\n",
    "# Optional: set the device to run\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1\"\n",
    "\n",
    "import time\n",
    "\n",
    "# Essential DS libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "# LightAutoML presets, task and report generation\n",
    "from lightautoml_gpu.automl.presets.gpu.tabular_gpu_presets import TabularAutoMLGPU\n",
    "from lightautoml_gpu.tasks import Task\n",
    "from lightautoml_gpu.report.gpu import ReportDeco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.064234,
     "end_time": "2021-06-22T20:11:01.619010",
     "exception": false,
     "start_time": "2021-06-22T20:11:01.554776",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 0.2. Constants\n",
    "\n",
    "Here we setup the constants to use in the kernel:\n",
    "- `N_THREADS` - number of vCPUs for LightAutoML model creation\n",
    "- `N_FOLDS` - number of folds in LightAutoML inner CV\n",
    "- `RANDOM_STATE` - random seed for better reproducibility\n",
    "- `TEST_SIZE` - houldout data part size \n",
    "- `TIMEOUT` - limit in seconds for model to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:11:01.758476Z",
     "iopub.status.busy": "2021-06-22T20:11:01.757403Z",
     "iopub.status.idle": "2021-06-22T20:11:01.760870Z",
     "shell.execute_reply": "2021-06-22T20:11:01.760168Z",
     "shell.execute_reply.started": "2021-06-22T19:06:51.523697Z"
    },
    "papermill": {
     "duration": 0.077787,
     "end_time": "2021-06-22T20:11:01.761030",
     "exception": false,
     "start_time": "2021-06-22T20:11:01.683243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "TIMEOUT = 300\n",
    "N_THREADS = 4\n",
    "N_FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = './data/'\n",
    "DATASET_NAMES = ['higgs.csv', 'Fashion-MNIST.csv']\n",
    "DATASET_FULLNAME = [os.path.join(DATASET_DIR, name) for name in DATASET_NAMES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.072033,
     "end_time": "2021-06-22T20:11:02.238196",
     "exception": false,
     "start_time": "2021-06-22T20:11:02.166163",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 0.3. Data loading\n",
    "Let's check the data we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:11:02.386568Z",
     "iopub.status.busy": "2021-06-22T20:11:02.385526Z",
     "iopub.status.idle": "2021-06-22T20:11:15.017602Z",
     "shell.execute_reply": "2021-06-22T20:11:15.018159Z",
     "shell.execute_reply.started": "2021-06-22T19:06:51.545269Z"
    },
    "papermill": {
     "duration": 12.710747,
     "end_time": "2021-06-22T20:11:15.018360",
     "exception": false,
     "start_time": "2021-06-22T20:11:02.307613",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4545/3578130192.py:1: DtypeWarning: Columns (20,21,22,23,24,25,26,27,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('./data/higgs.csv')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./data/higgs.csv')\n",
    "data.head()\n",
    "\n",
    "data_info_ = {\n",
    "                'path': 'openml/higgs.csv',\n",
    "                'target': 'class',\n",
    "                'task_type': 'binary',\n",
    "                'read_csv_params': {'na_values': '?'}\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "for col in data.columns:\n",
    "    if data[col].isin(['?']).any():\n",
    "        data[col] = data[col].replace('?', np.nan).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.065323,
     "end_time": "2021-06-22T20:11:21.676311",
     "exception": false,
     "start_time": "2021-06-22T20:11:21.610988",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 0.4 Data splitting for train-holdout\n",
    "As we have only one file with target values, we can split it into 80%-20% for holdout usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:11:21.814622Z",
     "iopub.status.busy": "2021-06-22T20:11:21.813630Z",
     "iopub.status.idle": "2021-06-22T20:11:22.537639Z",
     "shell.execute_reply": "2021-06-22T20:11:22.537037Z",
     "shell.execute_reply.started": "2021-06-22T19:07:07.916060Z"
    },
    "papermill": {
     "duration": 0.793619,
     "end_time": "2021-06-22T20:11:22.537798",
     "exception": false,
     "start_time": "2021-06-22T20:11:21.744179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splitted. Parts sizes: tr_data = (78440, 29), te_data = (19610, 29)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>lepton_pT</th>\n",
       "      <th>lepton_eta</th>\n",
       "      <th>lepton_phi</th>\n",
       "      <th>missing_energy_magnitude</th>\n",
       "      <th>missing_energy_phi</th>\n",
       "      <th>jet1pt</th>\n",
       "      <th>jet1eta</th>\n",
       "      <th>jet1phi</th>\n",
       "      <th>jet1b-tag</th>\n",
       "      <th>...</th>\n",
       "      <th>jet4eta</th>\n",
       "      <th>jet4phi</th>\n",
       "      <th>jet4b-tag</th>\n",
       "      <th>m_jj</th>\n",
       "      <th>m_jjj</th>\n",
       "      <th>m_lv</th>\n",
       "      <th>m_jlv</th>\n",
       "      <th>m_bb</th>\n",
       "      <th>m_wbb</th>\n",
       "      <th>m_wwbb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.033086</td>\n",
       "      <td>-0.027325</td>\n",
       "      <td>0.556388</td>\n",
       "      <td>0.716491</td>\n",
       "      <td>-1.623269</td>\n",
       "      <td>1.044414</td>\n",
       "      <td>-0.149550</td>\n",
       "      <td>-1.633134</td>\n",
       "      <td>2.173076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.891493</td>\n",
       "      <td>0.128023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.221998</td>\n",
       "      <td>1.333303</td>\n",
       "      <td>1.101426</td>\n",
       "      <td>0.886849</td>\n",
       "      <td>1.525385</td>\n",
       "      <td>1.250846</td>\n",
       "      <td>1.042270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.149442</td>\n",
       "      <td>0.240516</td>\n",
       "      <td>-1.208732</td>\n",
       "      <td>0.803575</td>\n",
       "      <td>1.224382</td>\n",
       "      <td>0.504847</td>\n",
       "      <td>0.587181</td>\n",
       "      <td>0.661531</td>\n",
       "      <td>1.086538</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.587601</td>\n",
       "      <td>-0.081836</td>\n",
       "      <td>3.101961</td>\n",
       "      <td>1.161402</td>\n",
       "      <td>1.038688</td>\n",
       "      <td>1.479556</td>\n",
       "      <td>1.069424</td>\n",
       "      <td>0.603161</td>\n",
       "      <td>0.783799</td>\n",
       "      <td>0.821149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.669081</td>\n",
       "      <td>0.802496</td>\n",
       "      <td>1.645025</td>\n",
       "      <td>1.346262</td>\n",
       "      <td>-1.145997</td>\n",
       "      <td>0.690627</td>\n",
       "      <td>-1.126907</td>\n",
       "      <td>0.855008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040348</td>\n",
       "      <td>-1.595084</td>\n",
       "      <td>3.101961</td>\n",
       "      <td>1.037140</td>\n",
       "      <td>0.983492</td>\n",
       "      <td>0.995939</td>\n",
       "      <td>0.926378</td>\n",
       "      <td>0.886266</td>\n",
       "      <td>0.912128</td>\n",
       "      <td>0.883060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.444346</td>\n",
       "      <td>-0.500674</td>\n",
       "      <td>-0.364785</td>\n",
       "      <td>0.716306</td>\n",
       "      <td>0.833619</td>\n",
       "      <td>0.939249</td>\n",
       "      <td>-0.048547</td>\n",
       "      <td>-0.799354</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.398159</td>\n",
       "      <td>0.857178</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.584398</td>\n",
       "      <td>1.213435</td>\n",
       "      <td>0.983564</td>\n",
       "      <td>0.895563</td>\n",
       "      <td>0.841721</td>\n",
       "      <td>1.141312</td>\n",
       "      <td>0.922072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.434464</td>\n",
       "      <td>0.240516</td>\n",
       "      <td>-0.117872</td>\n",
       "      <td>1.407808</td>\n",
       "      <td>1.084599</td>\n",
       "      <td>1.574911</td>\n",
       "      <td>-1.624993</td>\n",
       "      <td>0.106601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089573</td>\n",
       "      <td>-0.513003</td>\n",
       "      <td>3.101961</td>\n",
       "      <td>1.234359</td>\n",
       "      <td>1.151361</td>\n",
       "      <td>0.988237</td>\n",
       "      <td>0.614409</td>\n",
       "      <td>0.679219</td>\n",
       "      <td>0.704437</td>\n",
       "      <td>0.701936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  lepton_pT  lepton_eta  lepton_phi  missing_energy_magnitude  \\\n",
       "0      1   1.033086   -0.027325    0.556388                  0.716491   \n",
       "1      1   2.149442    0.240516   -1.208732                  0.803575   \n",
       "2      0   0.669081    0.802496    1.645025                  1.346262   \n",
       "3      0   0.444346   -0.500674   -0.364785                  0.716306   \n",
       "4      0   0.434464    0.240516   -0.117872                  1.407808   \n",
       "\n",
       "   missing_energy_phi    jet1pt   jet1eta   jet1phi  jet1b-tag  ...   jet4eta  \\\n",
       "0           -1.623269  1.044414 -0.149550 -1.633134   2.173076  ...  0.891493   \n",
       "1            1.224382  0.504847  0.587181  0.661531   1.086538  ... -0.587601   \n",
       "2           -1.145997  0.690627 -1.126907  0.855008   0.000000  ...  0.040348   \n",
       "3            0.833619  0.939249 -0.048547 -0.799354   0.000000  ... -2.398159   \n",
       "4            1.084599  1.574911 -1.624993  0.106601   0.000000  ... -0.089573   \n",
       "\n",
       "    jet4phi  jet4b-tag      m_jj     m_jjj      m_lv     m_jlv      m_bb  \\\n",
       "0  0.128023   0.000000  1.221998  1.333303  1.101426  0.886849  1.525385   \n",
       "1 -0.081836   3.101961  1.161402  1.038688  1.479556  1.069424  0.603161   \n",
       "2 -1.595084   3.101961  1.037140  0.983492  0.995939  0.926378  0.886266   \n",
       "3  0.857178   0.000000  1.584398  1.213435  0.983564  0.895563  0.841721   \n",
       "4 -0.513003   3.101961  1.234359  1.151361  0.988237  0.614409  0.679219   \n",
       "\n",
       "      m_wbb    m_wwbb  \n",
       "0  1.250846  1.042270  \n",
       "1  0.783799  0.821149  \n",
       "2  0.912128  0.883060  \n",
       "3  1.141312  0.922072  \n",
       "4  0.704437  0.701936  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_data, te_data = train_test_split(\n",
    "    data, \n",
    "    test_size=TEST_SIZE, \n",
    "    stratify=data['class'], \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f'Data splitted. Parts sizes: tr_data = {tr_data.shape}, te_data = {te_data.shape}')\n",
    "tr_data = tr_data.reset_index(drop=True)\n",
    "te_data = te_data.reset_index(drop=True)\n",
    "tr_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.071526,
     "end_time": "2021-06-22T20:11:22.853156",
     "exception": false,
     "start_time": "2021-06-22T20:11:22.781630",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Task definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Task type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "On the cell below we create Task object - the class to setup what task LightAutoML model should solve with specific loss and metric if necessary (more info can be found [here](https://lightautoml.readthedocs.io/en/latest/generated/lightautoml.tasks.base.Task.html#lightautoml.tasks.base.Task) in our documentation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:11:23.005952Z",
     "iopub.status.busy": "2021-06-22T20:11:23.002234Z",
     "iopub.status.idle": "2021-06-22T20:11:23.009732Z",
     "shell.execute_reply": "2021-06-22T20:11:23.010398Z",
     "shell.execute_reply.started": "2021-06-22T19:07:08.656347Z"
    },
    "papermill": {
     "duration": 0.086442,
     "end_time": "2021-06-22T20:11:23.010643",
     "exception": false,
     "start_time": "2021-06-22T20:11:22.924201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "task = Task('binary', device='gpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.070103,
     "end_time": "2021-06-22T20:11:23.150929",
     "exception": false,
     "start_time": "2021-06-22T20:11:23.080826",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1.2. Feature roles setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.069372,
     "end_time": "2021-06-22T20:11:23.290153",
     "exception": false,
     "start_time": "2021-06-22T20:11:23.220781",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To solve the task, we need to setup columns roles. The **only role you must setup is target role**, everything else (drop, numeric, categorical, group, weights etc.) is up to user - LightAutoML models have automatic columns typization inside:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:11:23.434600Z",
     "iopub.status.busy": "2021-06-22T20:11:23.433707Z",
     "iopub.status.idle": "2021-06-22T20:11:23.438088Z",
     "shell.execute_reply": "2021-06-22T20:11:23.438653Z",
     "shell.execute_reply.started": "2021-06-22T19:07:08.673897Z"
    },
    "papermill": {
     "duration": 0.07715,
     "end_time": "2021-06-22T20:11:23.438830",
     "exception": false,
     "start_time": "2021-06-22T20:11:23.361680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "roles = {\n",
    "    'target': 'class',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.074284,
     "end_time": "2021-06-22T20:11:23.582462",
     "exception": false,
     "start_time": "2021-06-22T20:11:23.508178",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1.3. LightAutoML model creation - TabularAutoML preset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.072649,
     "end_time": "2021-06-22T20:11:23.726154",
     "exception": false,
     "start_time": "2021-06-22T20:11:23.653505",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In next the cell we are going to create LightAutoML model with `TabularAutoML` class - preset with default model structure like in the image below:\n",
    "\n",
    "<img src=\"../../imgs/tutorial_blackbox_pipeline.png\" alt=\"TabularAutoML preset pipeline\" style=\"width:85%;\"/>\n",
    "\n",
    "in just several lines. Let's discuss the params we can setup:\n",
    "- `task` - the type of the ML task (the only **must have** parameter)\n",
    "- `timeout` - time limit in seconds for model to train\n",
    "- `cpu_limit` - vCPU count for model to use\n",
    "- `reader_params` - parameter change for Reader object inside preset, which works on the first step of data preparation: automatic feature typization, preliminary almost-constant features, correct CV setup etc. For example, we setup `n_jobs` threads for typization algo, `cv` folds and `random_state` as inside CV seed.\n",
    "\n",
    "**Important note**: `reader_params` key is one of the YAML config keys, which is used inside `TabularAutoML` preset. [More details](https://github.com/sberbank-ai-lab/LightAutoML/blob/master/lightautoml/automl/presets/tabular_config.yml) on its structure with explanation comments can be found on the link attached. Each key from this config can be modified with user settings during preset object initialization. To get more info about different parameters setting (for example, ML algos which can be used in `general_params->use_algos`) please take a look at our [article on TowardsDataScience](https://towardsdatascience.com/lightautoml-preset-usage-tutorial-2cce7da6f936).\n",
    "\n",
    "Moreover, to receive the automatic report for our model we will use `ReportDeco` decorator and work with the decorated version in the same way as we do with usual one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = TabularAutoMLGPU(task=task,    \n",
    "                          reader_params = {'n_jobs': 2, 'cv': N_FOLDS, 'random_state': RANDOM_STATE},\n",
    "    timeout=TIMEOUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. AutoML training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run autoML training use fit_predict method:\n",
    "\n",
    "- `train_data` - Dataset to train.\n",
    "- `roles` - Roles dict.\n",
    "- `verbose` - Controls the verbosity: the higher, the more messages.\n",
    "        <1  : messages are not displayed;\n",
    "        >=1 : the computation process for layers is displayed;\n",
    "        >=2 : the information about folds processing is also displayed;\n",
    "        >=3 : the hyperparameters optimization process is also displayed;\n",
    "        >=4 : the training process for every algorithm is displayed;\n",
    "\n",
    "Note: out-of-fold prediction is calculated during training and returned from the fit_predict method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:14:23] Stdout logging level is INFO.\n",
      "[11:14:23] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
      "[11:14:23] Task: binary\n",
      "\n",
      "[11:14:23] Start automl preset with listed constraints:\n",
      "[11:14:23] - time: 300.00 seconds\n",
      "[11:14:23] - CPU: 4 cores\n",
      "[11:14:23] - memory: 16 GB\n",
      "\n",
      "[11:14:23] Train data shape: (78440, 29)\n",
      "[11:14:32] Feats was rejected during automatic roles guess: []\n",
      "[11:14:32] Layer \u001b[1m1\u001b[0m train process start. Time left 291.06 secs\n",
      "[11:14:32] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[11:14:44] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7598962501666371\u001b[0m\n",
      "[11:14:44] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[11:14:44] Time left 279.46 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: less than 75% gpu memory available for training. Free: 23141.5 Total: 32510.5\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:14:56] \u001b[1mSelector_CatBoostGPU\u001b[0m fitting and predicting completed\n",
      "[11:14:56] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoostGPU\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: less than 75% gpu memory available for training. Free: 23137.5 Total: 32510.5\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Warning: less than 75% gpu memory available for training. Free: 23131.5 Total: 32510.5\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:15:18] Time limit exceeded after calculating fold 1\n",
      "[11:15:18] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoostGPU\u001b[0m finished. score = \u001b[1m0.8085333969760496\u001b[0m\n",
      "[11:15:18] \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoostGPU\u001b[0m fitting and predicting completed\n",
      "[11:15:18] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_XGB\u001b[0m ...\n",
      "[11:15:39] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_XGB\u001b[0m finished. score = \u001b[1m0.8064250733140045\u001b[0m\n",
      "[11:15:39] \u001b[1mLvl_0_Pipe_1_Mod_2_XGB\u001b[0m fitting and predicting completed\n",
      "[11:15:39] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_XGB\u001b[0m ... Time budget is 128.75 secs\n",
      "[11:17:50] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_XGB\u001b[0m completed\n",
      "[11:17:50] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_XGB\u001b[0m ...\n",
      "[11:18:04] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_XGB\u001b[0m finished. score = \u001b[1m0.8077146571412942\u001b[0m\n",
      "[11:18:04] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_XGB\u001b[0m fitting and predicting completed\n",
      "[11:18:04] Time left 78.74 secs\n",
      "\n",
      "[11:18:04] Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n",
      "[11:18:04] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[11:18:04] Blending: Optimization starts with equal weights and score 0.8055075402680416\n",
      "[11:18:05] Blending, iter 0: score = 0.8091622571244707, weights = [0.         0.38308454 0.22414874 0.3927667 ]\n",
      "[11:18:05] Blending, iter 1: score = 0.8091652919895407, weights = [0.         0.35871977 0.2359575  0.40532276]\n",
      "[11:18:05] Blending, iter 2: score = 0.8091652919895407, weights = [0.         0.35871974 0.23595749 0.40532273]\n",
      "[11:18:05] Blending, iter 3: score = 0.8091652919895407, weights = [0.         0.35871974 0.23595749 0.40532273]\n",
      "[11:18:05] No score update. Terminated\n",
      "[11:18:05] \u001b[1mAutoml preset training completed in 222.16 seconds\u001b[0m\n",
      "\n",
      "[11:18:05] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.35872 * (2 averaged models Lvl_0_Pipe_1_Mod_0_CatBoostGPU) +\n",
      "\t 0.23596 * (5 averaged models Lvl_0_Pipe_1_Mod_2_XGB) +\n",
      "\t 0.40532 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_XGB) \n",
      "\n",
      "CPU times: user 3min 53s, sys: 37.2 s, total: 4min 30s\n",
      "Wall time: 3min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "oof_pred = automl.fit_predict(tr_data, roles = roles, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.145098,
     "end_time": "2021-06-22T20:34:32.530768",
     "exception": false,
     "start_time": "2021-06-22T20:34:32.385670",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Prediction on holdout and model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for te_data:\n",
      "array([[0.4453373 ],\n",
      "       [0.3911723 ],\n",
      "       [0.87689215],\n",
      "       ...,\n",
      "       [0.6192466 ],\n",
      "       [0.89121807],\n",
      "       [0.67450213]], dtype=float32)\n",
      "Shape = (19610, 1)\n",
      "CPU times: user 330 ms, sys: 12.3 ms, total: 342 ms\n",
      "Wall time: 539 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "te_pred = automl.predict(te_data)\n",
    "print(f'Prediction for te_data:\\n{te_pred}\\nShape = {te_pred.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF score: 0.8091652926417789\n",
      "HOLDOUT score: 0.8116664670828967\n"
     ]
    }
   ],
   "source": [
    "auc_val = roc_auc_score(tr_data[data_info_['target']].values, oof_pred.data[:, 0])\n",
    "print(f'OOF score: {auc_val}')\n",
    "auc_test = roc_auc_score(te_data[data_info_['target']].values, te_pred.data[:, 0])\n",
    "print(f'HOLDOUT score: {auc_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can obtain the description of the resulting pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prediction for new objects (level 0) = \n",
      "\t 0.35872 * (2 averaged models Lvl_0_Pipe_1_Mod_0_CatBoostGPU) +\n",
      "\t 0.23596 * (5 averaged models Lvl_0_Pipe_1_Mod_2_XGB) +\n",
      "\t 0.40532 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_XGB) \n"
     ]
    }
   ],
   "source": [
    "print(automl.create_model_str_desc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also for this purposes LightAutoML have ReportDeco, use it to build reports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-06-22T20:11:23.898451Z",
     "iopub.status.busy": "2021-06-22T20:11:23.882755Z",
     "iopub.status.idle": "2021-06-22T20:28:33.962394Z",
     "shell.execute_reply": "2021-06-22T20:28:33.962995Z",
     "shell.execute_reply.started": "2021-06-22T19:07:31.468238Z"
    },
    "papermill": {
     "duration": 1030.159528,
     "end_time": "2021-06-22T20:28:33.963476",
     "exception": false,
     "start_time": "2021-06-22T20:11:23.803948",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "RD = ReportDeco(output_path = 'tabularAutoML_model_report')\n",
    "\n",
    "automl_rd = RD(\n",
    "    TabularAutoMLGPU(\n",
    "        task = task, \n",
    "        timeout = TIMEOUT,\n",
    "        reader_params = {'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': RANDOM_STATE}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:06] Stdout logging level is INFO.\n",
      "[11:18:06] Task: binary\n",
      "\n",
      "[11:18:06] Start automl preset with listed constraints:\n",
      "[11:18:06] - time: 300.00 seconds\n",
      "[11:18:06] - CPU: 4 cores\n",
      "[11:18:06] - memory: 16 GB\n",
      "\n",
      "[11:18:06] Train data shape: (78440, 29)\n",
      "[11:18:16] Feats was rejected during automatic roles guess: []\n",
      "[11:18:16] Layer \u001b[1m1\u001b[0m train process start. Time left 290.02 secs\n",
      "[11:18:16] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[11:18:25] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7598962501666371\u001b[0m\n",
      "[11:18:25] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[11:18:25] Time left 280.35 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:37] \u001b[1mSelector_CatBoostGPU\u001b[0m fitting and predicting completed\n",
      "[11:18:37] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoostGPU\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:00] Time limit exceeded after calculating fold 1\n",
      "[11:19:00] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoostGPU\u001b[0m finished. score = \u001b[1m0.808178117586074\u001b[0m\n",
      "[11:19:00] \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoostGPU\u001b[0m fitting and predicting completed\n",
      "[11:19:00] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_XGB\u001b[0m ...\n",
      "[11:19:22] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_XGB\u001b[0m finished. score = \u001b[1m0.8064250733140045\u001b[0m\n",
      "[11:19:22] \u001b[1mLvl_0_Pipe_1_Mod_2_XGB\u001b[0m fitting and predicting completed\n",
      "[11:19:22] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_XGB\u001b[0m ... Time budget is 126.02 secs\n",
      "[11:21:32] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_XGB\u001b[0m completed\n",
      "[11:21:32] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_XGB\u001b[0m ...\n",
      "[11:21:46] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_XGB\u001b[0m finished. score = \u001b[1m0.8077146571412942\u001b[0m\n",
      "[11:21:46] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_XGB\u001b[0m fitting and predicting completed\n",
      "[11:21:46] Time left 79.42 secs\n",
      "\n",
      "[11:21:46] Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n",
      "[11:21:46] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[11:21:46] Blending: Optimization starts with equal weights and score 0.8054692382228301\n",
      "[11:21:47] Blending, iter 0: score = 0.8091111066358864, weights = [0.         0.36614463 0.22984143 0.40401396]\n",
      "[11:21:47] Blending, iter 1: score = 0.8091149365795122, weights = [0.         0.33970565 0.24498025 0.41531408]\n",
      "[11:21:47] Blending, iter 2: score = 0.8091149365795122, weights = [0.         0.33970565 0.24498025 0.41531405]\n",
      "[11:21:47] Blending, iter 3: score = 0.8091148791825369, weights = [0.         0.33970568 0.24498028 0.4153141 ]\n",
      "[11:21:47] Blending, iter 4: score = 0.8091148791825369, weights = [0.         0.33970568 0.24498028 0.4153141 ]\n",
      "[11:21:47] No score update. Terminated\n",
      "[11:21:48] \u001b[1mAutoml preset training completed in 221.70 seconds\u001b[0m\n",
      "\n",
      "[11:21:48] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.33971 * (2 averaged models Lvl_0_Pipe_1_Mod_0_CatBoostGPU) +\n",
      "\t 0.24498 * (5 averaged models Lvl_0_Pipe_1_Mod_2_XGB) +\n",
      "\t 0.41531 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_XGB) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anton/GLAMA/LightAutoML_GPU/lightautoml_gpu/report/gpu/report_deco_gpu.py:141: FutureWarning: \n",
      "\n",
      "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
      "This will become an error in seaborn v0.14.0; please update your code.\n",
      "\n",
      "  sns.kdeplot(\n",
      "/home/anton/GLAMA/LightAutoML_GPU/lightautoml_gpu/report/gpu/report_deco_gpu.py:148: FutureWarning: \n",
      "\n",
      "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
      "This will become an error in seaborn v0.14.0; please update your code.\n",
      "\n",
      "  sns.kdeplot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 1s, sys: 42.7 s, total: 4min 43s\n",
      "Wall time: 3min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "oof_pred = automl_rd.fit_predict(tr_data, roles = roles, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the report is available in tabularAutoML_model_report folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_importance.png\t\t       test_roc_curve_1.png\r\n",
      "lama_interactive_report.html\t       valid_distribution_of_logits.png\r\n",
      "test_distribution_of_logits_1.png      valid_pie_f1_metric.png\r\n",
      "test_pie_f1_metric_1.png\t       valid_pr_curve.png\r\n",
      "test_pr_curve_1.png\t\t       valid_preds_distribution_by_bins.png\r\n",
      "test_preds_distribution_by_bins_1.png  valid_roc_curve.png\r\n"
     ]
    }
   ],
   "source": [
    "!ls tabularAutoML_model_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:34:32.909392Z",
     "iopub.status.busy": "2021-06-22T20:34:32.850821Z",
     "iopub.status.idle": "2021-06-22T20:34:55.170012Z",
     "shell.execute_reply": "2021-06-22T20:34:55.170702Z",
     "shell.execute_reply.started": "2021-06-22T19:36:39.413930Z"
    },
    "papermill": {
     "duration": 22.483603,
     "end_time": "2021-06-22T20:34:55.170931",
     "exception": false,
     "start_time": "2021-06-22T20:34:32.687328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anton/GLAMA/LightAutoML_GPU/lightautoml_gpu/report/gpu/report_deco_gpu.py:141: FutureWarning: \n",
      "\n",
      "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
      "This will become an error in seaborn v0.14.0; please update your code.\n",
      "\n",
      "  sns.kdeplot(\n",
      "/home/anton/GLAMA/LightAutoML_GPU/lightautoml_gpu/report/gpu/report_deco_gpu.py:148: FutureWarning: \n",
      "\n",
      "`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
      "This will become an error in seaborn v0.14.0; please update your code.\n",
      "\n",
      "  sns.kdeplot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for te_data:\n",
      "array([[0.4418166 ],\n",
      "       [0.3866924 ],\n",
      "       [0.8699182 ],\n",
      "       ...,\n",
      "       [0.61608374],\n",
      "       [0.89125025],\n",
      "       [0.6804474 ]], dtype=float32)\n",
      "Shape = (19610, 1)\n",
      "CPU times: user 6.95 s, sys: 4.17 s, total: 11.1 s\n",
      "Wall time: 2.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "te_pred = automl_rd.predict(te_data)\n",
    "print(f'Prediction for te_data:\\n{te_pred}\\nShape = {te_pred.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T20:34:55.470121Z",
     "iopub.status.busy": "2021-06-22T20:34:55.468938Z",
     "iopub.status.idle": "2021-06-22T20:34:55.629520Z",
     "shell.execute_reply": "2021-06-22T20:34:55.630295Z",
     "shell.execute_reply.started": "2021-06-22T19:37:24.055023Z"
    },
    "papermill": {
     "duration": 0.310292,
     "end_time": "2021-06-22T20:34:55.630539",
     "exception": false,
     "start_time": "2021-06-22T20:34:55.320247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF score: 0.8091149385362273\n",
      "HOLDOUT score: 0.8117723169223295\n"
     ]
    }
   ],
   "source": [
    "auc_val = roc_auc_score(tr_data[data_info_['target']].values, oof_pred.data[:, 0])\n",
    "print(f'OOF score: {auc_val}')\n",
    "auc_test = roc_auc_score(te_data[data_info_['target']].values, te_pred.data[:, 0])\n",
    "print(f'HOLDOUT score: {auc_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Multi-GPU results\n",
    "\n",
    "Here is an example of how to run Multi-GPU configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``cluster`` is an object that connects all GPUS and handles their communication. You should pass indices of GPUs that you want to use for LAMA training through parameter `CUDA_VISIBLE_DEVICES`.\n",
    "\n",
    "Also, other specifications are passed to `cluster` but you can leave these parameters unchanged, as shown in the example.\n",
    "\n",
    "After that, an instance of `client` is created and it should be passed to `automl` object if you want to run multi-GPU training.\n",
    "\n",
    "Finally you can run training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anton/.conda/envs/rapids-23.02/lib/python3.8/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 34015 instead\n",
      "  warnings.warn(\n",
      "2023-10-12 11:21:55,883 - distributed.comm.ucx - WARNING - A CUDA context for device 0 (b'GPU-b0462d46-9248-fcb0-0ee8-63a5eda3462b') already exists on process ID 4545. This is often the result of a CUDA-enabled library calling a CUDA runtime function before Dask-CUDA can spawn worker processes. Please make sure any such function calls don't happen at import time or in the global scope of a program.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1697109715.898943] [automlgpu:4545 :0]          parser.c:1908 UCX  WARN  unused env variable: UCX_MEMTYPE_CACHE (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-12 11:21:57,865 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-tsyldut0', purging\n",
      "2023-10-12 11:21:57,866 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-aaesqj3s', purging\n",
      "2023-10-12 11:21:57,866 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n",
      "2023-10-12 11:21:57,866 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n",
      "2023-10-12 11:21:57,992 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize\n",
      "2023-10-12 11:21:57,992 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ucx://127.0.0.1:48475': None, 'ucx://127.0.0.1:57647': None}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster = LocalCUDACluster(rmm_managed_memory=True, CUDA_VISIBLE_DEVICES=\"0, 1\",\n",
    "                               protocol=\"ucx\", enable_nvlink=True,\n",
    "                               memory_limit=\"30GB\")\n",
    "\n",
    "client = Client(cluster)\n",
    "client.run(cudf.set_allocator, \"managed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:22:02] Stdout logging level is INFO.\n",
      "[11:22:02] Task: binary\n",
      "\n",
      "[11:22:02] Start automl preset with listed constraints:\n",
      "[11:22:02] - time: 300.00 seconds\n",
      "[11:22:02] - CPU: 4 cores\n",
      "[11:22:02] - memory: 16 GB\n",
      "\n",
      "[11:22:02] Train data shape: (78440, 29)\n",
      "[11:22:10] Feats was rejected during automatic roles guess: []\n",
      "[11:22:10] Layer \u001b[1m1\u001b[0m train process start. Time left 292.15 secs\n",
      "[11:22:10] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[11:22:30] Time limit exceeded after calculating fold(s) [0 1]\n",
      "[11:22:30] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7619489118408146\u001b[0m\n",
      "[11:22:30] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[11:22:30] Time left 271.66 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:22:41] \u001b[1mSelector_CatBoostGPU\u001b[0m fitting and predicting completed\n",
      "[11:22:42] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoostGPU\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:23:03] Time limit exceeded after calculating fold(s) [2 3]\n",
      "[11:23:03] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoostGPU\u001b[0m finished. score = \u001b[1m0.8061328238067021\u001b[0m\n",
      "[11:23:03] \u001b[1mLvl_0_Pipe_1_Mod_0_CatBoostGPU\u001b[0m fitting and predicting completed\n",
      "[11:23:03] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_XGB\u001b[0m ...\n",
      "[11:23:19] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_XGB\u001b[0m finished. score = \u001b[1m0.8064250733140045\u001b[0m\n",
      "[11:23:19] \u001b[1mLvl_0_Pipe_1_Mod_2_XGB\u001b[0m fitting and predicting completed\n",
      "[11:23:19] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_XGB\u001b[0m ... Time budget is 97.50 secs\n",
      "[11:25:05] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_XGB\u001b[0m completed\n",
      "[11:25:05] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_XGB\u001b[0m ...\n",
      "[11:25:16] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_XGB\u001b[0m finished. score = \u001b[1m0.8082896600400371\u001b[0m\n",
      "[11:25:16] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_XGB\u001b[0m fitting and predicting completed\n",
      "[11:25:16] Time left 105.90 secs\n",
      "\n",
      "[11:25:16] Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n",
      "[11:25:16] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[11:25:16] Blending: Optimization starts with equal weights and score 0.8085730696720829\n",
      "[11:25:16] Blending, iter 0: score = 0.810175005882342, weights = [0.         0.35854208 0.19807272 0.4433852 ]\n",
      "[11:25:16] Blending, iter 1: score = 0.8101775652656505, weights = [0.         0.33655822 0.22481287 0.43862888]\n",
      "[11:25:17] Blending, iter 2: score = 0.810177828117708, weights = [0.         0.3443052  0.22218773 0.43350706]\n",
      "[11:25:17] Blending, iter 3: score = 0.810177828117708, weights = [0.         0.3443052  0.22218773 0.43350706]\n",
      "[11:25:17] No score update. Terminated\n",
      "[11:25:17] \u001b[1mAutoml preset training completed in 195.13 seconds\u001b[0m\n",
      "\n",
      "[11:25:17] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.34431 * (4 averaged models Lvl_0_Pipe_1_Mod_0_CatBoostGPU) +\n",
      "\t 0.22219 * (5 averaged models Lvl_0_Pipe_1_Mod_2_XGB) +\n",
      "\t 0.43351 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_XGB) \n",
      "\n",
      "CPU times: user 4min 12s, sys: 1min 7s, total: 5min 19s\n",
      "Wall time: 3min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# task = Task(task_types['higgs.csv'], device='mgpu')\n",
    "\n",
    "automl = TabularAutoMLGPU(\n",
    "    task=Task('binary', device='mgpu'),\n",
    "    timeout=TIMEOUT,\n",
    "    config_path='./data/dp.yml',\n",
    "    client=client,\n",
    "    general_params = {'parallel_folds': True} # stands for compute parallel. True for DataParallel\n",
    ")\n",
    "\n",
    "\n",
    "oof_pred = automl.fit_predict(tr_data, roles = roles, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_pred = automl.predict(te_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4493517 ],\n",
       "       [0.37712663],\n",
       "       [0.8564067 ],\n",
       "       ...,\n",
       "       [0.6270436 ],\n",
       "       [0.90256083],\n",
       "       [0.6837865 ]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl.predict(te_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOLDOUT score: 0.8122404752233056\n"
     ]
    }
   ],
   "source": [
    "auc_test = roc_auc_score(te_data[data_info_['target']].values, te_pred.data[:, 0])\n",
    "print(f'HOLDOUT score: {auc_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.14221,
     "end_time": "2021-06-22T20:35:48.782561",
     "exception": false,
     "start_time": "2021-06-22T20:35:48.640351",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Additional materials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.147943,
     "end_time": "2021-06-22T20:35:49.074531",
     "exception": false,
     "start_time": "2021-06-22T20:35:48.926588",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- [Official LightAutoML github repo](https://github.com/sberbank-ai-lab/LightAutoML)\n",
    "- [LightAutoML documentation](https://lightautoml.readthedocs.io/en/latest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-23.02",
   "language": "python",
   "name": "rapids-23.02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1531.539656,
   "end_time": "2021-06-22T20:35:52.076563",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-22T20:10:20.536907",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
